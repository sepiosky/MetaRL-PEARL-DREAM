Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.11121568828821182
Distance: 7.916738510131836
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.823922157287598
Distance: 7.927954196929932
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 6])
Action: noop
Reward: -0.10325802117586136
Distance: 0.004032120108604431
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 6])
Action: left
Reward: -0.09800423681735992
Distance: 0.007290138863027096
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.0969453975558281
Distance: 0.005294374190270901
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.10041311383247375
Distance: 0.0022397683933377266
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.10097107291221619
Distance: 0.0026528791058808565
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.10110395401716232
Distance: 0.0036239484325051308
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.10032947361469269
Distance: 0.004727900959551334
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: end_episode
Reward: -0.102125383913517
Distance: 0.00505737354978919
Next state: tensor([3, 2, 1, 0])
================================================================================

