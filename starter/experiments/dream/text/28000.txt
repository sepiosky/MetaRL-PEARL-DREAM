Env ID: [18]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.11812267452478409
Distance: 8.739218711853027
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.033368684351444244
Distance: 8.757341384887695
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.1409202516078949
Distance: 8.690710067749023
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.16403350234031677
Distance: 8.731630325317383
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.12222728878259659
Distance: 8.795663833618164
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.1088777557015419
Distance: 8.817891120910645
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.10570678859949112
Distance: 8.82676887512207
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.729284286499023
Distance: 8.832475662231445
Next state: tensor([ 4,  2,  0, 19])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 4,  2,  0, 19])
Action: left
Reward: -0.09901038557291031
Distance: 0.003190593561157584
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: end_episode
Reward: -0.10145048052072525
Distance: 0.0022009778767824173
Next state: tensor([3, 2, 1, 0])
================================================================================

