Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.05961046367883682
Distance: 7.148815631866455
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.04586372524499893
Distance: 7.108426094055176
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.08902464061975479
Distance: 7.054289817810059
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 1, 0])
Action: up
Reward: -0.0701361671090126
Distance: 7.043314456939697
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 4, 0, 0])
Action: down
Reward: -0.13463935256004333
Distance: 7.013450622558594
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 1, 0])
Action: down
Reward: 0.06882848590612411
Distance: 7.048089981079102
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1604042947292328
Distance: 6.879261493682861
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: right
Reward: 6.785919189453125
Distance: 6.939665794372559
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 4])
Action: left
Reward: -0.06123964115977287
Distance: 0.05374662205576897
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: right
Reward: -0.10284760594367981
Distance: 0.014986260794103146
Next state: tensor([4, 2, 0, 4])
================================================================================

