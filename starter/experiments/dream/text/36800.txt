Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.1210547462105751
Distance: 7.623122692108154
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 3, 1, 0])
Action: noop
Reward: 0.015219591557979584
Distance: 7.644177436828613
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 3, 1, 0])
Action: right
Reward: -0.08883485943078995
Distance: 7.528957843780518
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0])
Action: drop
Reward: -0.05412159115076065
Distance: 7.517792701721191
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0])
Action: drop
Reward: -0.09072408825159073
Distance: 7.471914291381836
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0])
Action: right
Reward: -0.08024606853723526
Distance: 7.4626383781433105
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 0, 0])
Action: down
Reward: 7.336255073547363
Distance: 7.44288444519043
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 7])
Action: end_episode
Reward: -0.09407688677310944
Distance: 0.006629284005612135
Next state: tensor([4, 2, 0, 7])
================================================================================

