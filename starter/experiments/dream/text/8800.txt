Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.16111239790916443
Distance: 7.506723403930664
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.13104304671287537
Distance: 7.567835807800293
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.14551743865013123
Distance: 7.598878860473633
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.17435941100120544
Distance: 7.6443963050842285
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.01430521160364151
Distance: 7.718755722045898
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.026854611933231354
Distance: 7.633060932159424
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.416712284088135
Distance: 7.559915542602539
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 6])
Action: left
Reward: -0.07581815868616104
Distance: 0.0432034507393837
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09394492208957672
Distance: 0.01902160793542862
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.09802544116973877
Distance: 0.012966525740921497
Next state: tensor([2, 1, 1, 0])
================================================================================

