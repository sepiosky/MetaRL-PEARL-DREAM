Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.023993588984012604
Distance: 7.354491710662842
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.14344558119773865
Distance: 7.278485298156738
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.14672145247459412
Distance: 7.321930885314941
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.12330064922571182
Distance: 7.36865234375
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 1, 1, 0])
Action: up
Reward: 0.09127654880285263
Distance: 7.391952991485596
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.021432973444461823
Distance: 7.200676441192627
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.08897600322961807
Distance: 7.122109413146973
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.061463452875614166
Distance: 7.111085414886475
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1, 0])
Action: pickup
Reward: -0.16966399550437927
Distance: 7.072548866271973
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 1, 0])
Action: ride_bus
Reward: -0.2502323091030121
Distance: 7.142212867736816
Next state: tensor([0, 0, 1, 0])
================================================================================

