Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.12264976650476456
Distance: 8.628969192504883
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.14698371291160583
Distance: 8.651618957519531
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.594541549682617
Distance: 8.698602676391602
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 5])
Action: right
Reward: -0.10006926953792572
Distance: 0.004060917999595404
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 5])
Action: noop
Reward: -0.09877514839172363
Distance: 0.004130184650421143
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 5])
Action: drop
Reward: -0.1000489741563797
Distance: 0.0029053278267383575
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 5])
Action: ride_bus
Reward: -0.09998916834592819
Distance: 0.0029543042182922363
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 5])
Action: end_episode
Reward: -0.10026111453771591
Distance: 0.002943469909951091
Next state: tensor([4, 2, 0, 5])
================================================================================

