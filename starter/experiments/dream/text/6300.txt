Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.12621745467185974
Distance: 10.36599349975586
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.07252559810876846
Distance: 10.392210960388184
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.95760440826416
Distance: 10.364736557006836
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 8])
Action: left
Reward: 0.1890588104724884
Distance: 0.30713218450546265
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.09450630843639374
Distance: 0.01807338371872902
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.09444142878055573
Distance: 0.012579689733684063
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.1021624282002449
Distance: 0.007021116558462381
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10294076055288315
Distance: 0.009183540008962154
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10370875149965286
Distance: 0.012124297209084034
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10453428328037262
Distance: 0.0158330500125885
Next state: tensor([3, 2, 1, 0])
================================================================================

