Env ID: [22]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.13202723860740662
Distance: 8.69648265838623
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.620966911315918
Distance: 8.728509902954102
Next state: tensor([ 4,  2,  0, 23])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 23])
Action: right
Reward: -0.09982767701148987
Distance: 0.007542523089796305
Next state: tensor([ 4,  2,  0, 23])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 4,  2,  0, 23])
Action: noop
Reward: -0.0977107509970665
Distance: 0.007370199076831341
Next state: tensor([ 4,  2,  0, 23])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 4,  2,  0, 23])
Action: right
Reward: -0.10060340166091919
Distance: 0.00508094672113657
Next state: tensor([ 4,  2,  0, 23])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 4,  2,  0, 23])
Action: left
Reward: -0.09994957596063614
Distance: 0.005684344097971916
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09786174446344376
Distance: 0.005633915774524212
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.09966312348842621
Distance: 0.0034956582821905613
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.10003150999546051
Distance: 0.003158782608807087
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.10018559545278549
Distance: 0.0031902878545224667
Next state: tensor([2, 2, 0, 0])
================================================================================

