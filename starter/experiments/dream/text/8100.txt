Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.12521705031394958
Distance: 8.47137451171875
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.0921550765633583
Distance: 8.496591567993164
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10946808010339737
Distance: 8.488746643066406
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.1058116927742958
Distance: 8.498214721679688
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.5303760766983032
Distance: 8.504026412963867
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 1, 0, 0])
Action: up
Reward: -0.018466569483280182
Distance: 8.934402465820312
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.663938522338867
Distance: 8.852869033813477
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 5])
Action: left
Reward: -0.03713998198509216
Distance: 0.08893010020256042
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.09327597916126251
Distance: 0.026070082560181618
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 1, 0, 0])
Action: up
Reward: -0.09657450765371323
Distance: 0.01934606395661831
Next state: tensor([3, 2, 1, 0])
================================================================================

