Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.05461130291223526
Distance: 6.948253631591797
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: up
Reward: 0.0009740814566612244
Distance: 6.902864933013916
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.11625394970178604
Distance: 6.801890850067139
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.147742360830307
Distance: 6.818144798278809
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: right
Reward: 6.755092620849609
Distance: 6.86588716506958
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 5])
Action: ride_bus
Reward: -0.09221449494361877
Distance: 0.010794559493660927
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 5])
Action: up
Reward: -0.09942431002855301
Distance: 0.0030090566724538803
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 0, 0])
Action: noop
Reward: -0.09922095388174057
Distance: 0.002433365909382701
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 3, 0, 0])
Action: noop
Reward: -0.09980564564466476
Distance: 0.0016543194651603699
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 0, 0])
Action: up
Reward: -0.10111832618713379
Distance: 0.0014599638525396585
Next state: tensor([4, 4, 1, 0])
================================================================================

