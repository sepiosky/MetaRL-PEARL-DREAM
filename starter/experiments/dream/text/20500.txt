Env ID: [2]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.15024718642234802
Distance: 10.185821533203125
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.12510070204734802
Distance: 10.236068725585938
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 3, 1, 0])
Action: right
Reward: -0.17881354689598083
Distance: 10.26116943359375
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0])
Action: down
Reward: -0.13711032271385193
Distance: 10.339982986450195
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: right
Reward: 10.263208389282227
Distance: 10.377093315124512
Next state: tensor([4, 2, 0, 3])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 3])
Action: left
Reward: -0.08833752572536469
Distance: 0.013884598389267921
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10035225749015808
Distance: 0.0022221235558390617
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.09915132075548172
Distance: 0.0025743800215423107
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.09970816969871521
Distance: 0.001725700101815164
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.09998726844787598
Distance: 0.0014338658656924963
Next state: tensor([3, 2, 1, 0])
================================================================================

