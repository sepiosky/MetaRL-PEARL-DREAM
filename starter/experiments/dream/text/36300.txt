Env ID: [11]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.11754856258630753
Distance: 8.949553489685059
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.038469888269901276
Distance: 8.96710205078125
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0, 0])
Action: right
Reward: -0.1762615144252777
Distance: 8.905571937561035
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0])
Action: down
Reward: 8.880026817321777
Distance: 8.981833457946777
Next state: tensor([ 4,  2,  0, 12])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 4,  2,  0, 12])
Action: left
Reward: -0.09911762177944183
Distance: 0.0018060157308354974
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09974607080221176
Distance: 0.0009236335754394531
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.09970948845148087
Distance: 0.0006696998025290668
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.1000826507806778
Distance: 0.00037918423186056316
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.10011889785528183
Distance: 0.0004618298262357712
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.1001068577170372
Distance: 0.0005807235720567405
Next state: tensor([2, 2, 0, 0])
================================================================================

