Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.124852754175663
Distance: 7.575329780578613
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 3, 1, 0])
Action: down
Reward: -0.09988460689783096
Distance: 7.60018253326416
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.13618525862693787
Distance: 7.600067138671875
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: left
Reward: -0.11928138881921768
Distance: 7.636252403259277
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 2, 0, 0])
Action: noop
Reward: 0.01911010593175888
Distance: 7.655533790588379
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 2, 0, 0])
Action: right
Reward: -0.04007873684167862
Distance: 7.536423683166504
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 1, 0])
Action: left
Reward: -0.17453059554100037
Distance: 7.476502418518066
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 2, 0, 0])
Action: left
Reward: -0.15140876173973083
Distance: 7.551033020019531
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 2, 0, 0])
Action: ride_bus
Reward: -0.19986066222190857
Distance: 7.602441787719727
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 2, 0, 0])
Action: left
Reward: -0.10729274898767471
Distance: 7.7023024559021
Next state: tensor([0, 2, 0, 0])
================================================================================

