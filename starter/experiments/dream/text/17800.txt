Env ID: [8]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.14326247572898865
Distance: 7.641871929168701
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.13343676924705505
Distance: 7.685134410858154
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.14942893385887146
Distance: 7.718571186065674
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: drop
Reward: 0.3646668493747711
Distance: 7.76800012588501
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.3100648820400238
Distance: 7.303333282470703
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.14894351363182068
Distance: 7.513398170471191
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.14198073744773865
Distance: 7.562341690063477
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.09319934993982315
Distance: 7.60432243347168
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.483558654785156
Distance: 7.597521781921387
Next state: tensor([4, 2, 0, 9])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 2, 0, 9])
Action: noop
Reward: -0.09534232318401337
Distance: 0.013963012024760246
Next state: tensor([4, 2, 0, 9])
================================================================================

