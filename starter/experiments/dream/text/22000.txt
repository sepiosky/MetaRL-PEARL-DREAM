Env ID: [15]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.0773378387093544
Distance: 9.821737289428711
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.69640064239502
Distance: 9.79907512664795
Next state: tensor([ 4,  2,  0, 16])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 16])
Action: left
Reward: -0.09835047274827957
Distance: 0.0026739896275103092
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10016053169965744
Distance: 0.001024462515488267
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.09969034790992737
Distance: 0.0011849903967231512
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.09966707229614258
Distance: 0.0008753358270041645
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 1, 0])
Action: up
Reward: -0.09999801963567734
Distance: 0.0005424050032161176
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 3, 0, 0])
Action: noop
Reward: -0.1002662256360054
Distance: 0.0005404261755757034
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 3, 0, 0])
Action: end_episode
Reward: -0.10005586594343185
Distance: 0.0008066524169407785
Next state: tensor([1, 3, 0, 0])
================================================================================

