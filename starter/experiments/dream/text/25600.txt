Env ID: [0]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.08747635036706924
Distance: 8.081445693969727
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.967350482940674
Distance: 8.06892204284668
Next state: tensor([4, 2, 0, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 1])
Action: left
Reward: -0.09917958080768585
Distance: 0.0015719765797257423
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10096706449985504
Distance: 0.0007515555480495095
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.09884866327047348
Distance: 0.0017186161130666733
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0])
Action: end_episode
Reward: -0.09990012645721436
Distance: 0.0005672755651175976
Next state: tensor([3, 3, 0, 0])
================================================================================

