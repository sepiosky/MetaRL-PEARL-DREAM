Env ID: [1]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.31391677260398865
Distance: 10.711950302124023
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.007606126368045807
Distance: 10.925867080688477
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.09583625942468643
Distance: 10.833473205566406
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.21714171767234802
Distance: 10.829309463500977
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 2, 1, 0])
Action: up
Reward: 0.1921028196811676
Distance: 10.946451187133789
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 3, 0, 0])
Action: down
Reward: -0.18890723586082458
Distance: 10.654348373413086
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 1, 0])
Action: down
Reward: -0.2688671052455902
Distance: 10.743255615234375
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 1, 0, 0])
Action: ride_bus
Reward: -0.14015063643455505
Distance: 10.91212272644043
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 1, 0, 0])
Action: noop
Reward: -0.3319574296474457
Distance: 10.95227336883545
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 1, 0, 0])
Action: down
Reward: -0.07327041774988174
Distance: 11.18423080444336
Next state: tensor([1, 0, 0, 0])
================================================================================

