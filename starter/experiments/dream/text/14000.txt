Env ID: [8]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.14392337203025818
Distance: 7.970330238342285
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.12784728407859802
Distance: 8.014253616333008
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.92328405380249
Distance: 8.04210090637207
Next state: tensor([4, 2, 0, 9])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 9])
Action: up
Reward: -0.09540672600269318
Distance: 0.018816597759723663
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0])
Action: ride_bus
Reward: -0.0971837267279625
Distance: 0.014223320409655571
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.09994296729564667
Distance: 0.011407045647501945
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0])
Action: right
Reward: -0.09756960719823837
Distance: 0.011350014247000217
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 0, 0])
Action: ride_bus
Reward: -0.10111837089061737
Distance: 0.00891962181776762
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.10166951268911362
Distance: 0.010037994012236595
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 3, 0, 0])
Action: end_episode
Reward: -0.10267315059900284
Distance: 0.011707503348588943
Next state: tensor([3, 3, 0, 0])
================================================================================

