Env ID: [2]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.2592063844203949
Distance: 9.797531127929688
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.2803255021572113
Distance: 9.956737518310547
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.15105876326560974
Distance: 10.137063026428223
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.077092744410038
Distance: 10.188121795654297
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.07261715084314346
Distance: 10.165214538574219
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.13773879408836365
Distance: 10.137831687927246
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.16053256392478943
Distance: 10.175570487976074
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.06294288486242294
Distance: 10.236103057861328
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.2989097535610199
Distance: 10.073160171508789
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.3841587007045746
Distance: 10.272069931030273
Next state: tensor([3, 2, 1, 0])
================================================================================

